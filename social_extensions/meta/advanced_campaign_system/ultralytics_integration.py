"""
Advanced Campaign System - Ultralytics Integration
Flujo completo: 5 clips â†’ selecciÃ³n â†’ reasignaciÃ³n presupuesto â†’ escalado automÃ¡tico â†’ reinversiÃ³n YouTube
"""

import os
import json
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, field
from pathlib import Path
import random
from datetime import datetime
import subprocess
import tempfile
import shutil

# Import simulado de OpenCV y Ultralytics (dummy implementation)
try:
    # En modo producciÃ³n, usar: import cv2, from ultralytics import YOLO
    # import cv2
    # import ultralytics
    HAS_ULTRALYTICS = False  # Forzar modo dummy para desarrollo
except ImportError:
    HAS_ULTRALYTICS = False

@dataclass
class ClipAnalysis:
    """AnÃ¡lisis completo de un clip de video"""
    clip_id: str
    file_path: str
    duration: float
    resolution: Tuple[int, int]
    frame_count: int
    
    # AnÃ¡lisis visual con YOLO
    object_detections: List[Dict]  # Objetos detectados
    scene_analysis: Dict[str, float]  # Tipos de escena y confianza
    visual_complexity: float  # Complejidad visual (0-1)
    
    # MÃ©tricas de calidad
    visual_quality_score: float  # Calidad visual general
    engagement_indicators: Dict[str, float]  # Indicadores de engagement
    virality_potential: float  # Potencial de viralidad
    
    # AnÃ¡lisis de contenido
    genre_classification: Dict[str, float]  # GÃ©nero musical detectado
    mood_analysis: Dict[str, float]  # AnÃ¡lisis de mood/ambiente
    target_audience: List[str]  # Audiencia objetivo inferida

@dataclass
class ClipPerformanceData:
    """Datos de rendimiento de clips de campaÃ±as anteriores"""
    clip_id: str
    campaign_id: str
    initial_budget: float
    total_views: int
    ctr: float
    cpc: float
    cpv: float
    engagement_rate: float
    conversion_rate: float
    roi: float
    geographic_performance: Dict[str, float]
    demographic_breakdown: Dict[str, Dict]
    was_winner: bool

@dataclass
class ScalingDecision:
    """DecisiÃ³n de escalado para un clip ganador"""
    clip_id: str
    confidence_score: float
    scaling_factor: float  # Multiplicador de presupuesto
    target_platforms: List[str]
    budget_reallocation: Dict[str, float]
    predicted_performance: Dict[str, float]
    risk_assessment: str
    scaling_timeline: str

class DummyYOLOAnalyzer:
    """Simulador de anÃ¡lisis YOLO para desarrollo sin GPU"""
    
    def __init__(self):
        self.model_name = "yolov8x.pt"
        self.confidence_threshold = 0.5
        
        # Objetos comunes en videos musicales
        self.common_objects = [
            'person', 'car', 'motorcycle', 'traffic light', 'stop sign',
            'chair', 'couch', 'tv', 'laptop', 'cell phone', 'bottle',
            'wine glass', 'cup', 'microphone', 'guitar', 'keyboard'
        ]
        
        # Tipos de escena tÃ­picos
        self.scene_types = [
            'urban_street', 'club_interior', 'studio_recording', 'car_interior',
            'rooftop', 'beach', 'concert_venue', 'mansion_interior'
        ]
    
    def analyze_video_clip(self, video_path: str) -> ClipAnalysis:
        """Simula anÃ¡lisis completo de un clip de video"""
        print(f"ğŸ¬ Analizando clip: {Path(video_path).name}")
        
        # Simular propiedades bÃ¡sicas del video
        duration = random.uniform(15, 45)  # Entre 15-45 segundos
        resolution = random.choice([(1920, 1080), (1080, 1920), (1280, 720)])
        frame_count = int(duration * 30)  # 30 fps
        
        # Simular detecciones de objetos
        num_detections = random.randint(3, 12)
        object_detections = []
        
        for _ in range(num_detections):
            obj = random.choice(self.common_objects)
            detection = {
                'class': obj,
                'confidence': random.uniform(0.5, 0.95),
                'bbox': [
                    random.randint(0, resolution[0]//2),
                    random.randint(0, resolution[1]//2),
                    random.randint(100, 300),
                    random.randint(100, 300)
                ],
                'frame_number': random.randint(1, frame_count)
            }
            object_detections.append(detection)
        
        # AnÃ¡lisis de escena
        scene_analysis = {}
        for scene_type in random.sample(self.scene_types, 3):
            scene_analysis[scene_type] = random.uniform(0.1, 0.9)
        
        # Normalizar confianzas de escena
        total_confidence = sum(scene_analysis.values())
        scene_analysis = {k: v/total_confidence for k, v in scene_analysis.items()}
        
        # Calcular complejidad visual
        visual_complexity = min(len(object_detections) / 15.0, 1.0)
        
        # Calcular calidad visual
        visual_quality_score = random.uniform(0.6, 0.95)
        
        # Indicadores de engagement
        engagement_indicators = {
            'people_count': len([d for d in object_detections if d['class'] == 'person']),
            'dynamic_movement': random.uniform(0.3, 0.9),
            'color_vibrancy': random.uniform(0.4, 0.8),
            'scene_transitions': random.randint(2, 8),
            'visual_effects': random.uniform(0.2, 0.7)
        }
        
        # Potencial de viralidad basado en mÃºltiples factores
        virality_factors = [
            visual_quality_score,
            engagement_indicators['dynamic_movement'],
            engagement_indicators['color_vibrancy'],
            min(engagement_indicators['people_count'] / 5.0, 1.0),
            visual_complexity
        ]
        virality_potential = sum(virality_factors) / len(virality_factors)
        
        # ClasificaciÃ³n de gÃ©nero (simplificada)
        genre_classification = {
            'trap': random.uniform(0.1, 0.8),
            'reggaeton': random.uniform(0.1, 0.8),
            'rap': random.uniform(0.1, 0.6),
            'corrido': random.uniform(0.1, 0.4)
        }
        
        # Normalizar gÃ©neros
        total_genre = sum(genre_classification.values())
        genre_classification = {k: v/total_genre for k, v in genre_classification.items()}
        
        # AnÃ¡lisis de mood
        mood_analysis = {
            'energetic': random.uniform(0.2, 0.9),
            'chill': random.uniform(0.1, 0.7),
            'aggressive': random.uniform(0.1, 0.6),
            'romantic': random.uniform(0.1, 0.5),
            'party': random.uniform(0.2, 0.8)
        }
        
        # Audiencia objetivo inferida
        target_audience = []
        if engagement_indicators['people_count'] >= 3:
            target_audience.append('social_groups')
        if mood_analysis['energetic'] > 0.7:
            target_audience.append('young_adults')
        if mood_analysis['party'] > 0.6:
            target_audience.append('party_goers')
        if not target_audience:
            target_audience = ['general_music_fans']
        
        clip_id = Path(video_path).stem
        
        return ClipAnalysis(
            clip_id=clip_id,
            file_path=video_path,
            duration=duration,
            resolution=resolution,
            frame_count=frame_count,
            object_detections=object_detections,
            scene_analysis=scene_analysis,
            visual_complexity=visual_complexity,
            visual_quality_score=visual_quality_score,
            engagement_indicators=engagement_indicators,
            virality_potential=virality_potential,
            genre_classification=genre_classification,
            mood_analysis=mood_analysis,
            target_audience=target_audience
        )

class PerformancePredictor:
    """Predictor de rendimiento de clips basado en anÃ¡lisis visual y datos histÃ³ricos"""
    
    def __init__(self):
        self.historical_performance_db = []
        self.genre_multipliers = {
            'trap': 1.15,
            'reggaeton': 1.25,
            'rap': 1.05,
            'corrido': 0.95
        }
        
        self.platform_factors = {
            'meta_ads': 1.0,
            'tiktok_ads': 1.3,
            'youtube_ads': 0.8,
            'instagram_reels': 1.2
        }
    
    def load_historical_data(self, data_path: str = "/workspaces/master/data/clip_performance_history.json"):
        """Carga datos histÃ³ricos de rendimiento de clips"""
        try:
            if Path(data_path).exists():
                with open(data_path, 'r') as f:
                    data = json.load(f)
                    self.historical_performance_db = [ClipPerformanceData(**item) for item in data]
                    print(f"ğŸ“Š Cargados {len(self.historical_performance_db)} registros histÃ³ricos")
            else:
                print("ğŸ“Š No hay datos histÃ³ricos - usando predicciones base")
                self.generate_dummy_historical_data()
        except Exception as e:
            print(f"âš ï¸ Error cargando datos histÃ³ricos: {e}")
            self.generate_dummy_historical_data()
    
    def generate_dummy_historical_data(self):
        """Genera datos histÃ³ricos simulados para desarrollo"""
        print("ğŸ”„ Generando datos histÃ³ricos simulados...")
        
        for i in range(25):  # 25 clips histÃ³ricos
            performance = ClipPerformanceData(
                clip_id=f"clip_{i:03d}",
                campaign_id=f"campaign_{i//5:03d}",
                initial_budget=random.uniform(50, 150),
                total_views=random.randint(800, 5000),
                ctr=random.uniform(1.5, 4.5),
                cpc=random.uniform(0.30, 0.80),
                cpv=random.uniform(0.40, 0.60),
                engagement_rate=random.uniform(2.0, 8.0),
                conversion_rate=random.uniform(0.5, 3.0),
                roi=random.uniform(-50, 300),
                geographic_performance={
                    'ES': random.uniform(80, 200),
                    'MX': random.uniform(90, 180),
                    'CO': random.uniform(70, 160)
                },
                demographic_breakdown={
                    '18-24': {'views': random.randint(200, 800), 'engagement': random.uniform(3, 7)},
                    '25-34': {'views': random.randint(150, 600), 'engagement': random.uniform(2, 5)}
                },
                was_winner=random.random() > 0.7  # 30% fueron ganadores
            )
            self.historical_performance_db.append(performance)
        
        print(f"âœ… Generados {len(self.historical_performance_db)} registros simulados")
    
    def predict_clip_performance(self, clip_analysis: ClipAnalysis, 
                                budget: float = 100) -> Dict[str, float]:
        """Predice rendimiento de un clip basado en anÃ¡lisis visual"""
        
        # Score base de calidad
        base_score = clip_analysis.visual_quality_score
        
        # Boost por potencial de viralidad
        virality_boost = 1.0 + (clip_analysis.virality_potential - 0.5)
        
        # Multiplicador de gÃ©nero
        dominant_genre = max(clip_analysis.genre_classification, 
                           key=clip_analysis.genre_classification.get)
        genre_multiplier = self.genre_multipliers.get(dominant_genre, 1.0)
        
        # Factor de complejidad visual
        complexity_factor = 1.0 + (clip_analysis.visual_complexity * 0.3)
        
        # Factor de engagement por elementos detectados
        engagement_factor = 1.0
        if clip_analysis.engagement_indicators['people_count'] >= 2:
            engagement_factor *= 1.2
        if clip_analysis.engagement_indicators['dynamic_movement'] > 0.7:
            engagement_factor *= 1.15
        
        # Calcular mÃ©tricas predichas
        predicted_ctr = (2.5 * base_score * virality_boost * genre_multiplier * 
                        complexity_factor * engagement_factor)
        predicted_ctr = max(1.0, min(6.0, predicted_ctr))  # Limitar entre 1-6%
        
        predicted_cpv = 0.50 / (base_score * genre_multiplier)
        predicted_cpv = max(0.25, min(0.80, predicted_cpv))  # Limitar entre $0.25-$0.80
        
        predicted_engagement = (4.0 * base_score * virality_boost * engagement_factor)
        predicted_engagement = max(1.5, min(10.0, predicted_engagement))  # Limitar entre 1.5-10%
        
        predicted_views = int(budget / predicted_cpv)
        predicted_revenue = predicted_views * predicted_ctr / 100 * 15  # $15 por conversiÃ³n simulada
        predicted_roi = ((predicted_revenue - budget) / budget) * 100
        
        return {
            'predicted_ctr': predicted_ctr,
            'predicted_cpv': predicted_cpv,
            'predicted_engagement': predicted_engagement,
            'predicted_views': predicted_views,
            'predicted_revenue': predicted_revenue,
            'predicted_roi': predicted_roi,
            'confidence_score': base_score * 0.8 + virality_boost * 0.2,
            'dominant_genre': dominant_genre,
            'genre_confidence': clip_analysis.genre_classification[dominant_genre]
        }

class UltralyticsClipSelector:
    """Selector de clips usando anÃ¡lisis Ultralytics y ML"""
    
    def __init__(self):
        self.yolo_analyzer = DummyYOLOAnalyzer()
        self.performance_predictor = PerformancePredictor()
        self.performance_predictor.load_historical_data()
        
        # Criterios de selecciÃ³n
        self.selection_weights = {
            'visual_quality': 0.25,
            'virality_potential': 0.30,
            'predicted_roi': 0.25,
            'genre_confidence': 0.20
        }
    
    def analyze_clip_batch(self, clip_paths: List[str]) -> List[ClipAnalysis]:
        """Analiza un batch de clips con Ultralytics"""
        print("ğŸ¬ ANÃLISIS DE CLIPS CON ULTRALYTICS")
        print("-" * 45)
        
        analyses = []
        for i, clip_path in enumerate(clip_paths, 1):
            print(f"ğŸ“¹ Clip {i}/{len(clip_paths)}: {Path(clip_path).name}")
            
            # Verificar que el archivo existe (simulado)
            if not Path(clip_path).exists():
                print(f"   âš ï¸ Archivo no encontrado, usando anÃ¡lisis simulado")
            
            # AnÃ¡lisis con YOLO
            analysis = self.yolo_analyzer.analyze_video_clip(clip_path)
            
            # Mostrar resumen del anÃ¡lisis
            print(f"   ğŸ¯ Calidad visual: {analysis.visual_quality_score:.2f}")
            print(f"   ğŸš€ Potencial viral: {analysis.virality_potential:.2f}")
            print(f"   ğŸµ GÃ©nero dominante: {max(analysis.genre_classification, key=analysis.genre_classification.get)}")
            print(f"   ğŸ“Š Objetos detectados: {len(analysis.object_detections)}")
            print()
            
            analyses.append(analysis)
        
        return analyses
    
    def select_best_clips(self, clip_analyses: List[ClipAnalysis], 
                         budget_per_clip: float = 90,
                         num_selections: int = 3) -> List[Tuple[ClipAnalysis, Dict]]:
        """Selecciona los mejores clips basado en anÃ¡lisis ML"""
        print("ğŸ† SELECCIÃ“N DE CLIPS GANADORES")
        print("-" * 35)
        
        clip_scores = []
        
        for analysis in clip_analyses:
            # Obtener predicciÃ³n de rendimiento
            performance_pred = self.performance_predictor.predict_clip_performance(
                analysis, budget_per_clip
            )
            
            # Calcular score compuesto
            score = (
                analysis.visual_quality_score * self.selection_weights['visual_quality'] +
                analysis.virality_potential * self.selection_weights['virality_potential'] +
                (performance_pred['predicted_roi'] / 200) * self.selection_weights['predicted_roi'] +
                performance_pred['genre_confidence'] * self.selection_weights['genre_confidence']
            )
            
            clip_scores.append((analysis, performance_pred, score))
            
            print(f"ğŸ“¹ {analysis.clip_id}:")
            print(f"   ğŸ¯ Score total: {score:.3f}")
            print(f"   ğŸ“Š ROI predicho: {performance_pred['predicted_roi']:.1f}%")
            print(f"   ğŸ‘ï¸ CTR predicho: {performance_pred['predicted_ctr']:.2f}%")
            print(f"   ğŸ’° CPV predicho: ${performance_pred['predicted_cpv']:.3f}")
            print()
        
        # Ordenar por score descendente
        clip_scores.sort(key=lambda x: x[2], reverse=True)
        
        # Seleccionar top N
        selected = clip_scores[:num_selections]
        
        print("ğŸ… CLIPS SELECCIONADOS:")
        for i, (analysis, pred, score) in enumerate(selected, 1):
            print(f"   {i}. {analysis.clip_id} (Score: {score:.3f})")
        print()
        
        return [(analysis, pred) for analysis, pred, score in selected]
    
    def create_scaling_decisions(self, selected_clips: List[Tuple[ClipAnalysis, Dict]],
                               total_budget: float = 500) -> List[ScalingDecision]:
        """Crea decisiones de escalado para clips seleccionados"""
        print("ğŸ“ˆ CREANDO DECISIONES DE ESCALADO")
        print("-" * 35)
        
        scaling_decisions = []
        
        # Distribuir presupuesto basado en scores de confianza
        total_confidence = sum(pred['confidence_score'] for _, pred in selected_clips)
        
        for analysis, prediction in selected_clips:
            # Calcular factor de escalado basado en ROI predicho
            roi_factor = max(prediction['predicted_roi'] / 150, 0.5)  # MÃ­nimo 0.5x
            confidence_factor = prediction['confidence_score']
            
            scaling_factor = roi_factor * confidence_factor
            scaling_factor = max(0.5, min(3.0, scaling_factor))  # Limitar entre 0.5x y 3.0x
            
            # Asignar presupuesto proporcional
            budget_share = (prediction['confidence_score'] / total_confidence) * total_budget
            
            # Determinar plataformas objetivo
            target_platforms = ['meta_ads']
            if prediction['predicted_roi'] > 150:
                target_platforms.extend(['instagram_reels', 'tiktok_ads'])
            if scaling_factor > 2.0:
                target_platforms.append('youtube_ads')
            
            # ReasignaciÃ³n de presupuesto por plataforma
            budget_reallocation = {}
            base_budget = budget_share / len(target_platforms)
            for platform in target_platforms:
                platform_factor = self.performance_predictor.platform_factors.get(platform, 1.0)
                budget_reallocation[platform] = base_budget * platform_factor
            
            # Evaluar riesgo
            if prediction['confidence_score'] > 0.8 and prediction['predicted_roi'] > 100:
                risk_level = 'bajo'
            elif prediction['confidence_score'] > 0.6:
                risk_level = 'medio'
            else:
                risk_level = 'alto'
            
            # Timeline de escalado
            if scaling_factor > 2.0:
                timeline = 'inmediato'
            elif scaling_factor > 1.5:
                timeline = '24h'
            else:
                timeline = '48h'
            
            decision = ScalingDecision(
                clip_id=analysis.clip_id,
                confidence_score=prediction['confidence_score'],
                scaling_factor=scaling_factor,
                target_platforms=target_platforms,
                budget_reallocation=budget_reallocation,
                predicted_performance=prediction,
                risk_assessment=risk_level,
                scaling_timeline=timeline
            )
            
            scaling_decisions.append(decision)
            
            print(f"ğŸ¬ {analysis.clip_id}:")
            print(f"   ğŸ“Š Factor escalado: {scaling_factor:.2f}x")
            print(f"   ğŸ’° Presupuesto asignado: ${budget_share:.0f}")
            print(f"   ğŸ¯ Plataformas: {', '.join(target_platforms)}")
            print(f"   âš ï¸ Riesgo: {risk_level}")
            print(f"   â±ï¸ Timeline: {timeline}")
            print()
        
        return scaling_decisions

class AutomaticClipScaler:
    """Escalador automÃ¡tico de clips con reinversiÃ³n en YouTube"""
    
    def __init__(self):
        self.youtube_boost_multiplier = 2.5  # Multiplicador para boost de YouTube
        self.reinvestment_threshold = 150  # ROI mÃ­nimo para reinversiÃ³n
        
    def execute_scaling_plan(self, scaling_decisions: List[ScalingDecision]) -> Dict:
        """Ejecuta plan de escalado automÃ¡tico"""
        print("ğŸš€ EJECUTANDO ESCALADO AUTOMÃTICO")
        print("-" * 35)
        
        total_investment = 0
        total_predicted_views = 0
        total_predicted_revenue = 0
        
        youtube_reinvestment_budget = 0
        scaled_clips = []
        
        for decision in scaling_decisions:
            clip_budget = sum(decision.budget_reallocation.values())
            total_investment += clip_budget
            
            # Calcular vistas predichas para este clip
            predicted_views = decision.predicted_performance['predicted_views'] * decision.scaling_factor
            predicted_revenue = decision.predicted_performance['predicted_revenue'] * decision.scaling_factor
            
            total_predicted_views += predicted_views
            total_predicted_revenue += predicted_revenue
            
            # Evaluar para reinversiÃ³n en YouTube
            predicted_roi = decision.predicted_performance['predicted_roi']
            if predicted_roi > self.reinvestment_threshold:
                youtube_budget = clip_budget * 0.3  # 30% del presupuesto para YouTube
                youtube_reinvestment_budget += youtube_budget
                
                print(f"ğŸ“¹ {decision.clip_id}: Escalando {decision.scaling_factor:.1f}x")
                print(f"   ğŸ’° Presupuesto: ${clip_budget:.0f}")
                print(f"   ğŸ“º YouTube boost: ${youtube_budget:.0f}")
                print(f"   ğŸ‘€ Vistas predichas: {predicted_views:,.0f}")
                print(f"   â±ï¸ Timeline: {decision.scaling_timeline}")
            else:
                print(f"ğŸ“¹ {decision.clip_id}: Escalado conservador")
                print(f"   ğŸ’° Presupuesto: ${clip_budget:.0f}")
                print(f"   ğŸ‘€ Vistas predichas: {predicted_views:,.0f}")
            
            scaled_clips.append({
                'clip_id': decision.clip_id,
                'scaling_factor': decision.scaling_factor,
                'budget_allocated': clip_budget,
                'predicted_views': predicted_views,
                'predicted_revenue': predicted_revenue,
                'youtube_boost': youtube_budget if predicted_roi > self.reinvestment_threshold else 0,
                'platforms': decision.target_platforms,
                'risk_level': decision.risk_assessment
            })
            print()
        
        # Ejecutar boost de YouTube
        youtube_results = self.execute_youtube_boost(youtube_reinvestment_budget, scaled_clips)
        
        # Calcular ROI total
        total_roi = ((total_predicted_revenue - total_investment) / total_investment) * 100 if total_investment > 0 else 0
        
        execution_summary = {
            'total_investment': total_investment,
            'total_predicted_views': total_predicted_views,
            'total_predicted_revenue': total_predicted_revenue,
            'total_roi': total_roi,
            'youtube_boost_budget': youtube_reinvestment_budget,
            'youtube_boost_results': youtube_results,
            'scaled_clips': scaled_clips,
            'execution_timestamp': datetime.now().isoformat()
        }
        
        print("ğŸ“Š RESUMEN DE ESCALADO:")
        print(f"   ğŸ’° InversiÃ³n total: ${total_investment:.0f}")
        print(f"   ğŸ‘€ Vistas predichas: {total_predicted_views:,.0f}")
        print(f"   ğŸ“ˆ ROI predicho: {total_roi:.1f}%")
        print(f"   ğŸ“º Presupuesto YouTube: ${youtube_reinvestment_budget:.0f}")
        print()
        
        return execution_summary
    
    def execute_youtube_boost(self, boost_budget: float, scaled_clips: List[Dict]) -> Dict:
        """Ejecuta boost automÃ¡tico en YouTube"""
        if boost_budget <= 0:
            return {'boost_views': 0, 'boost_engagement': 0}
        
        print("ğŸ“º EJECUTANDO BOOST DE YOUTUBE")
        print("-" * 30)
        
        # Calcular vistas de boost (YouTube tÃ­picamente mÃ¡s caro pero mejor targeting)
        youtube_cpv = 0.08  # CPV mÃ¡s bajo en YouTube para mÃºsica
        boost_views = int(boost_budget / youtube_cpv)
        
        # Calcular engagement adicional (YouTube tiene mejor engagement para mÃºsica)
        boost_engagement_rate = 6.5  # 6.5% engagement rate en YouTube music
        boost_engagement = int(boost_views * boost_engagement_rate / 100)
        
        print(f"ğŸ’° Presupuesto boost: ${boost_budget:.0f}")
        print(f"ğŸ‘€ Vistas adicionales: {boost_views:,}")
        print(f"â¤ï¸ Engagement adicional: {boost_engagement:,}")
        print(f"ğŸ¯ CPV YouTube: ${youtube_cpv:.3f}")
        print()
        
        return {
            'boost_budget': boost_budget,
            'boost_views': boost_views,
            'boost_engagement': boost_engagement,
            'youtube_cpv': youtube_cpv,
            'engagement_rate': boost_engagement_rate
        }

class UltralyticsIntegration:
    """IntegraciÃ³n completa de Ultralytics para el sistema avanzado de campaÃ±as"""
    
    def __init__(self):
        self.clip_selector = UltralyticsClipSelector()
        self.auto_scaler = AutomaticClipScaler()
        
        # ConfiguraciÃ³n del flujo
        self.default_clip_budget = 90
        self.max_clips_to_select = 3
        self.total_scaling_budget = 500
        
    def execute_complete_flow(self, clip_directory: str = "/workspaces/master/data/video_clips/") -> Dict:
        """
        Ejecuta flujo completo: 5 clips â†’ anÃ¡lisis â†’ selecciÃ³n â†’ escalado â†’ YouTube
        """
        print("ğŸ¬ ULTRALYTICS INTEGRATION - FLUJO COMPLETO")
        print("=" * 50)
        
        # 1. Preparar clips simulados
        clip_paths = self.prepare_clip_paths(clip_directory)
        
        # 2. Analizar clips con Ultralytics
        clip_analyses = self.clip_selector.analyze_clip_batch(clip_paths)
        
        # 3. Seleccionar mejores clips
        selected_clips = self.clip_selector.select_best_clips(
            clip_analyses, 
            self.default_clip_budget,
            self.max_clips_to_select
        )
        
        # 4. Crear decisiones de escalado
        scaling_decisions = self.clip_selector.create_scaling_decisions(
            selected_clips,
            self.total_scaling_budget
        )
        
        # 5. Ejecutar escalado automÃ¡tico
        execution_results = self.auto_scaler.execute_scaling_plan(scaling_decisions)
        
        # 6. Compilar resultados finales
        complete_results = {
            'clips_analyzed': len(clip_analyses),
            'clips_selected': len(selected_clips),
            'clip_analyses': [
                {
                    'clip_id': analysis.clip_id,
                    'visual_quality': analysis.visual_quality_score,
                    'virality_potential': analysis.virality_potential,
                    'dominant_genre': max(analysis.genre_classification, key=analysis.genre_classification.get),
                    'target_audience': analysis.target_audience
                }
                for analysis in clip_analyses
            ],
            'selected_clips_summary': [
                {
                    'clip_id': analysis.clip_id,
                    'predicted_roi': pred['predicted_roi'],
                    'predicted_ctr': pred['predicted_ctr'],
                    'confidence': pred['confidence_score']
                }
                for analysis, pred in selected_clips
            ],
            'scaling_execution': execution_results,
            'process_timestamp': datetime.now().isoformat()
        }
        
        print("âœ… FLUJO COMPLETO TERMINADO")
        print("=" * 30)
        
        return complete_results
    
    def prepare_clip_paths(self, clip_directory: str) -> List[str]:
        """Prepara paths de clips (simulados para desarrollo)"""
        Path(clip_directory).mkdir(parents=True, exist_ok=True)
        
        # Crear clips simulados si no existen
        clip_names = [
            "trap_urbano_001.mp4",
            "reggaeton_perreo_002.mp4", 
            "rap_freestyle_003.mp4",
            "corrido_tumbado_004.mp4",
            "trap_melodico_005.mp4"
        ]
        
        clip_paths = []
        for clip_name in clip_names:
            clip_path = Path(clip_directory) / clip_name
            
            # Crear archivo dummy si no existe
            if not clip_path.exists():
                clip_path.touch()
            
            clip_paths.append(str(clip_path))
        
        print(f"ğŸ“ Preparados {len(clip_paths)} clips para anÃ¡lisis")
        return clip_paths

# Test completo del sistema
if __name__ == "__main__":
    print("ğŸ¬ TEST ULTRALYTICS INTEGRATION")
    print("=" * 40)
    
    # Crear instancia de integraciÃ³n
    ultralytics_integration = UltralyticsIntegration()
    
    # Ejecutar flujo completo
    results = ultralytics_integration.execute_complete_flow()
    
    # Mostrar resumen final
    print("ğŸ“Š RESUMEN FINAL:")
    print(f"   ğŸ¬ Clips analizados: {results['clips_analyzed']}")
    print(f"   ğŸ† Clips seleccionados: {results['clips_selected']}")
    print(f"   ğŸ’° InversiÃ³n total: ${results['scaling_execution']['total_investment']:.0f}")
    print(f"   ğŸ‘€ Vistas predichas: {results['scaling_execution']['total_predicted_views']:,.0f}")
    print(f"   ğŸ“ˆ ROI predicho: {results['scaling_execution']['total_roi']:.1f}%")
    print(f"   ğŸ“º YouTube boost: ${results['scaling_execution']['youtube_boost_budget']:.0f}")
    print(f"   ğŸ¥ Vistas YouTube: {results['scaling_execution']['youtube_boost_results']['boost_views']:,}")
    
    print("\nâœ… Ultralytics Integration implementado y testeado exitosamente!")