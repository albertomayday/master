#!/usr/bin/env python3
"""
Universal Dummy Mode Awakener
Sistema centralizado para despertar todos los componentes del proyecto
Genera ENVs autom√°ticamente, simula conexiones cloud y inicializa sistemas durmientes
"""

import os
import sys
import json
import yaml
import asyncio
import logging
import subprocess
import tempfile
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class ProjectBranch:
    """Configuration for each project branch"""
    name: str
    description: str
    main_dirs: List[str]
    required_services: List[str]
    env_template: Dict[str, str]
    dependencies: List[str]
    startup_commands: List[str]
    health_check_url: Optional[str] = None


@dataclass
class DummySystemConfig:
    """Master configuration for the entire dummy system"""
    project_root: Path
    active_branches: List[str]
    global_env: Dict[str, str]
    cloud_endpoints: Dict[str, str]
    simulation_level: str  # 'basic', 'full', 'production-ready'
    auto_wake_services: bool = True
    generate_test_data: bool = True


class CloudDatabaseSimulator:
    """Simulates cloud database connections and operations"""
    
    def __init__(self, config: DummySystemConfig):
        self.config = config
        self.mock_endpoints = {
            'postgresql': 'postgresql://dummy:dummy@localhost:5432/dummy_db',
            'mongodb': 'mongodb://dummy:dummy@localhost:27017/dummy_db',
            'redis': 'redis://localhost:6379/0',
            'elasticsearch': 'http://localhost:9200',
            'neo4j': 'bolt://localhost:7687',
            'timescale': 'postgresql://dummy:dummy@localhost:5433/timeseries_db'
        }
        
    async def create_mock_databases(self):
        """Create mock database structures"""
        logger.info("üóÑÔ∏è Creating mock cloud databases...")
        
        # Create SQLite files as local database mocks
        for db_type, connection_string in self.mock_endpoints.items():
            if 'postgresql' in db_type:
                await self._create_postgres_mock(db_type)
            elif 'mongodb' in db_type:
                await self._create_mongodb_mock(db_type)
            elif 'redis' in db_type:
                await self._create_redis_mock(db_type)
                
        logger.info("‚úÖ Mock databases created")
    
    async def _create_postgres_mock(self, db_name: str):
        """Create PostgreSQL mock with SQLite"""
        db_path = self.config.project_root / f"data/mock_databases/{db_name}.db"
        db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Create basic tables for different branches
        tables = {
            'rama': ['accounts', 'posts', 'analytics', 'ml_predictions'],
            'meta': ['campaigns', 'ads', 'audiences', 'budgets', 'performance'],
            'tele': ['contacts', 'exchanges', 'conversations', 'youtube_actions']
        }
        
        import sqlite3
        conn = sqlite3.connect(str(db_path))
        
        for branch, table_names in tables.items():
            for table in table_names:
                conn.execute(f"""
                    CREATE TABLE IF NOT EXISTS {branch}_{table} (
                        id INTEGER PRIMARY KEY,
                        created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                        data TEXT,
                        status TEXT DEFAULT 'active'
                    )
                """)
        
        conn.commit()
        conn.close()
        logger.info(f"‚úÖ Created mock PostgreSQL: {db_name}")
    
    async def _create_mongodb_mock(self, db_name: str):
        """Create MongoDB mock with JSON files"""
        db_path = self.config.project_root / f"data/mock_databases/{db_name}_collections"
        db_path.mkdir(parents=True, exist_ok=True)
        
        collections = ['users', 'sessions', 'events', 'metrics', 'logs']
        
        for collection in collections:
            collection_file = db_path / f"{collection}.json"
            if not collection_file.exists():
                collection_file.write_text(json.dumps([
                    {"_id": f"dummy_{i}", "data": f"mock_data_{i}", "timestamp": datetime.now().isoformat()}
                    for i in range(10)
                ], indent=2))
        
        logger.info(f"‚úÖ Created mock MongoDB: {db_name}")
    
    async def _create_redis_mock(self, db_name: str):
        """Create Redis mock with JSON file"""
        db_path = self.config.project_root / f"data/mock_databases/{db_name}_cache.json"
        db_path.parent.mkdir(parents=True, exist_ok=True)
        
        if not db_path.exists():
            cache_data = {
                "sessions": {f"session_{i}": {"user_id": f"user_{i}", "active": True} for i in range(100)},
                "counters": {"api_calls": 12345, "active_users": 567, "daily_posts": 89},
                "feature_flags": {"ml_enabled": True, "auto_posting": True, "debug_mode": True}
            }
            db_path.write_text(json.dumps(cache_data, indent=2))
        
        logger.info(f"‚úÖ Created mock Redis: {db_name}")


class UltralyticsSimulator:
    """Simulates Ultralytics YOLO integration"""
    
    def __init__(self, config: DummySystemConfig):
        self.config = config
        
    async def setup_mock_models(self):
        """Setup mock YOLO models"""
        logger.info("ü§ñ Setting up Ultralytics YOLO simulation...")
        
        models_dir = self.config.project_root / "data/models/mock_ultralytics"
        models_dir.mkdir(parents=True, exist_ok=True)
        
        # Create mock model files
        model_configs = {
            'yolov8n_screenshot.pt': {'type': 'screenshot', 'classes': ['button', 'text', 'image', 'video']},
            'yolov8s_video.pt': {'type': 'video', 'classes': ['person', 'face', 'object', 'scene']},
            'yolov8m_detection.pt': {'type': 'detection', 'classes': ['ui_element', 'popup', 'overlay']},
            'custom_tiktok.pt': {'type': 'tiktok', 'classes': ['like_button', 'share_button', 'comment', 'profile']}
        }
        
        for model_name, config in model_configs.items():
            model_path = models_dir / model_name
            config_path = models_dir / f"{model_name}.config.json"
            
            # Create mock model file (just a small text file)
            if not model_path.exists():
                model_path.write_text(f"Mock YOLO model: {model_name}\nGenerated: {datetime.now()}")
            
            # Create config file
            config_path.write_text(json.dumps(config, indent=2))
        
        # Create mock training data
        training_dir = models_dir / "training_data"
        training_dir.mkdir(exist_ok=True)
        
        datasets = ['screenshots', 'videos', 'ui_elements']
        for dataset in datasets:
            dataset_dir = training_dir / dataset
            dataset_dir.mkdir(exist_ok=True)
            
            # Create mock training metadata
            metadata = {
                'name': dataset,
                'samples': 1000,
                'classes': model_configs.get(f'yolov8n_{dataset}.pt', {}).get('classes', []),
                'last_training': datetime.now().isoformat(),
                'accuracy': 0.95
            }
            
            (dataset_dir / 'metadata.json').write_text(json.dumps(metadata, indent=2))
        
        logger.info("‚úÖ Ultralytics simulation setup complete")


class ENVGenerator:
    """Automatically generates environment files for all branches"""
    
    def __init__(self, config: DummySystemConfig):
        self.config = config
        
    async def generate_all_envs(self):
        """Generate ENV files for all project branches"""
        logger.info("üìù Generating environment files for all branches...")
        
        # Define branch-specific configurations
        branch_configs = {
            'rama': {
                'description': 'TikTok ML System (Main Branch)',
                'services': ['ml_api', 'device_farm', 'database', 'monitoring'],
                'env_vars': {
                    'DUMMY_MODE': 'true',
                    'ML_API_PORT': '8000',
                    'ML_API_HOST': '0.0.0.0',
                    'DATABASE_URL': 'postgresql://dummy:dummy@localhost:5432/tiktok_ml',
                    'REDIS_URL': 'redis://localhost:6379/0',
                    'YOLO_SCREENSHOT_IMPL': 'ml_core.models.yolo_screenshot.YoloScreenshotDetector',
                    'YOLO_VIDEO_IMPL': 'ml_core.models.yolo_video.YoloVideoDetector',
                    'ADB_CONTROLLER_IMPL': 'device_farm.controllers.adb_controller.ADBController',
                    'GOLOGIN_API_TOKEN': 'dummy_gologin_token',
                    'DEVICE_FARM_SIZE': '10',
                    'MONITORING_ENABLED': 'true',
                    'LOG_LEVEL': 'INFO'
                }
            },
            'meta': {
                'description': 'Meta Ads Automation System',
                'services': ['meta_api', 'telethon', 'gologin', 'database'],
                'env_vars': {
                    'DUMMY_MODE': 'true',
                    'TELEGRAM_API_ID': '12345',
                    'TELEGRAM_API_HASH': 'dummy_hash',
                    'TELEGRAM_PHONE': '+1234567890',
                    'META_ACCESS_TOKEN': 'dummy_meta_token',
                    'META_APP_ID': 'dummy_app_id',
                    'META_APP_SECRET': 'dummy_app_secret',
                    'GOLOGIN_API_TOKEN': 'dummy_gologin_token',
                    'DATABASE_URL': 'postgresql://dummy:dummy@localhost:5432/meta_ads',
                    'PROXY_LIST_URL': 'http://dummy-proxy-service/list',
                    'AUTO_CAMPAIGN_CREATION': 'true',
                    'DAILY_BUDGET_LIMIT': '100',
                    'LOG_LEVEL': 'INFO'
                }
            },
            'tele': {
                'description': 'Like4Like Telegram Automation',
                'services': ['telegram_bot', 'youtube_executor', 'database', 'gologin'],
                'env_vars': {
                    'DUMMY_MODE': 'true',
                    'TELEGRAM_API_ID': '12345',
                    'TELEGRAM_API_HASH': 'dummy_hash',
                    'TELEGRAM_PHONE': '+1234567890',
                    'TELEGRAM_BOT_TOKEN': 'dummy_bot_token',
                    'DATABASE_URL': 'postgresql://dummy:dummy@localhost:5432/like4like_bot',
                    'GOLOGIN_API_TOKEN': 'dummy_gologin_token',
                    'GOLOGIN_MAX_PROFILES': '5',
                    'YOUTUBE_MIN_WATCH_TIME': '30',
                    'YOUTUBE_MAX_WATCH_TIME': '300',
                    'YOUTUBE_MAX_ACTIONS_PER_DAY': '50',
                    'YOUTUBE_ENABLE_COMMENTS': 'true',
                    'SECURITY_HUMAN_DELAYS': 'true',
                    'LOG_LEVEL': 'INFO'
                }
            }
        }
        
        # Generate global .env file
        await self._generate_global_env()
        
        # Generate branch-specific .env files
        for branch_name, branch_config in branch_configs.items():
            await self._generate_branch_env(branch_name, branch_config)
        
        logger.info("‚úÖ All environment files generated")
    
    async def _generate_global_env(self):
        """Generate global environment file"""
        global_env_path = self.config.project_root / ".env"
        
        global_vars = {
            '# Universal Project Environment Variables': '',
            'PROJECT_ROOT': str(self.config.project_root),
            'DUMMY_MODE': 'true',
            'SIMULATION_LEVEL': self.config.simulation_level,
            'AUTO_WAKE_SERVICES': str(self.config.auto_wake_services).lower(),
            'GENERATE_TEST_DATA': str(self.config.generate_test_data).lower(),
            '': '',
            '# Global Database Configuration': '',
            'GLOBAL_DB_HOST': 'localhost',
            'GLOBAL_DB_PORT': '5432',
            'GLOBAL_DB_USER': 'dummy_user',
            'GLOBAL_DB_PASSWORD': 'dummy_password',
            '': '',
            '# Cloud Simulation Endpoints': '',
            **{f'CLOUD_{k.upper()}_URL': v for k, v in self.config.cloud_endpoints.items()},
            '': '',
            '# Monitoring and Logging': '',
            'LOG_LEVEL': 'INFO',
            'METRICS_ENABLED': 'true',
            'HEALTH_CHECK_INTERVAL': '300',
            'ALERT_WEBHOOK_URL': 'http://localhost:3000/alerts',
            '': '',
            '# Development Settings': '',
            'DEBUG_MODE': 'true', 
            'HOT_RELOAD': 'true',
            'API_DOCS_ENABLED': 'true',
            'CORS_ENABLED': 'true'
        }
        
        env_content = []
        for key, value in global_vars.items():
            if key.startswith('#') or key == '':
                env_content.append(f"{key}{value}")
            else:
                env_content.append(f"{key}={value}")
        
        global_env_path.write_text('\n'.join(env_content))
        logger.info(f"‚úÖ Generated global .env file")
    
    async def _generate_branch_env(self, branch_name: str, branch_config: Dict):
        """Generate branch-specific environment file"""
        branch_dir = self.config.project_root
        
        # Create branch-specific directories if they don't exist
        if branch_name == 'meta':
            branch_dir = branch_dir / "meta_automation"
        elif branch_name == 'tele':
            branch_dir = branch_dir / "telegram_automation"
        
        branch_dir.mkdir(exist_ok=True)
        env_path = branch_dir / f".env.{branch_name}"
        
        env_content = [
            f"# {branch_config['description']}",
            f"# Generated: {datetime.now().isoformat()}",
            f"# Branch: {branch_name}",
            "",
            "# Branch Configuration",
            f"BRANCH_NAME={branch_name}",
            f"SERVICES=" + ",".join(branch_config['services']),
            "",
            "# Environment Variables"
        ]
        
        for key, value in branch_config['env_vars'].items():
            env_content.append(f"{key}={value}")
        
        env_path.write_text('\n'.join(env_content))
        logger.info(f"‚úÖ Generated .env.{branch_name} file")


class ServiceOrchestrator:
    """Orchestrates the startup of all project services"""
    
    def __init__(self, config: DummySystemConfig):
        self.config = config
        self.running_processes = {}
        
    async def wake_all_services(self):
        """Wake up all services across all branches"""
        logger.info("üöÄ Waking up all project services...")
        
        # Service definitions for each branch
        services = {
            'rama': [
                {'name': 'ml_api', 'command': ['uvicorn', 'ml_core.api.main:app', '--port', '8000', '--reload'], 'cwd': self.config.project_root},
                {'name': 'device_farm', 'command': ['python', '-m', 'device_farm.controllers.device_manager'], 'cwd': self.config.project_root},
                {'name': 'monitoring', 'command': ['python', '-m', 'monitoring.health.account_health'], 'cwd': self.config.project_root}
            ],
            'meta': [
                {'name': 'meta_automation', 'command': ['python', 'main.py'], 'cwd': self.config.project_root / 'meta_automation'},
                {'name': 'telegram_monitor', 'command': ['python', 'telegram_monitor.py'], 'cwd': self.config.project_root / 'meta_automation'}
            ],
            'tele': [
                {'name': 'telegram_bot', 'command': ['python', 'main.py'], 'cwd': self.config.project_root / 'telegram_automation'}
            ]
        }
        
        # Start services based on active branches
        for branch_name in self.config.active_branches:
            if branch_name in services:
                await self._start_branch_services(branch_name, services[branch_name])
        
        # Start global monitoring service
        await self._start_global_monitoring()
        
        logger.info("‚úÖ All services awakened")
    
    async def _start_branch_services(self, branch_name: str, branch_services: List[Dict]):
        """Start services for a specific branch"""
        logger.info(f"üîß Starting {branch_name} branch services...")
        
        for service in branch_services:
            service_name = f"{branch_name}_{service['name']}"
            
            try:
                # Set environment variables
                env = os.environ.copy()
                env.update({
                    'DUMMY_MODE': 'true',
                    'BRANCH_NAME': branch_name,
                    'SERVICE_NAME': service['name']
                })
                
                # Start the service
                process = await asyncio.create_subprocess_exec(
                    *service['command'],
                    cwd=service['cwd'],
                    env=env,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                
                self.running_processes[service_name] = process
                logger.info(f"‚úÖ Started {service_name} (PID: {process.pid})")
                
            except Exception as e:
                logger.error(f"‚ùå Failed to start {service_name}: {e}")
    
    async def _start_global_monitoring(self):
        """Start global system monitoring"""
        logger.info("üìä Starting global monitoring...")
        
        # Create a simple monitoring script
        monitor_script = self.config.project_root / "dummy_monitor.py"
        monitor_script.write_text("""
import asyncio
import logging
import time
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('global_monitor')

async def monitor_services():
    while True:
        logger.info(f"üîç System health check - {datetime.now()}")
        logger.info("üìä All services operational in dummy mode")
        logger.info("üíæ Mock databases responding")
        logger.info("ü§ñ ML models loaded (dummy)")
        logger.info("üì± Device farm active (simulated)")
        await asyncio.sleep(60)

if __name__ == "__main__":
    asyncio.run(monitor_services())
""")
        
        # Start monitoring process
        try:
            env = os.environ.copy()
            env['DUMMY_MODE'] = 'true'
            
            process = await asyncio.create_subprocess_exec(
                'python', str(monitor_script),
                env=env,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            self.running_processes['global_monitor'] = process
            logger.info(f"‚úÖ Started global monitoring (PID: {process.pid})")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to start global monitoring: {e}")
    
    async def stop_all_services(self):
        """Stop all running services"""
        logger.info("üõë Stopping all services...")
        
        for service_name, process in self.running_processes.items():
            try:
                process.terminate()
                await process.wait()
                logger.info(f"‚úÖ Stopped {service_name}")
            except Exception as e:
                logger.error(f"‚ùå Error stopping {service_name}: {e}")
        
        self.running_processes.clear()


class UniversalAwakener:
    """Main class that orchestrates the entire dummy system awakening"""
    
    def __init__(self, project_root: str = None, branches: List[str] = None):
        self.project_root = Path(project_root or os.getcwd())
        self.active_branches = branches or ['rama', 'meta', 'tele']
        
        # Configuration
        self.config = DummySystemConfig(
            project_root=self.project_root,
            active_branches=self.active_branches,
            global_env={},
            cloud_endpoints={
                'postgresql': 'postgresql://dummy:dummy@localhost:5432',
                'mongodb': 'mongodb://dummy:dummy@localhost:27017',
                'redis': 'redis://localhost:6379',
                'elasticsearch': 'http://localhost:9200'
            },
            simulation_level='full',
            auto_wake_services=True,
            generate_test_data=True
        )
        
        # Components
        self.db_simulator = CloudDatabaseSimulator(self.config)
        self.ultralytics_simulator = UltralyticsSimulator(self.config)
        self.env_generator = ENVGenerator(self.config)
        self.service_orchestrator = ServiceOrchestrator(self.config)
    
    async def awaken_system(self, mode: str = 'full'):
        """Main method to awaken the entire system"""
        logger.info("üåÖ Starting Universal Dummy System Awakening...")
        logger.info(f"üìÅ Project root: {self.project_root}")
        logger.info(f"üåø Active branches: {', '.join(self.active_branches)}")
        logger.info(f"‚öôÔ∏è Mode: {mode}")
        
        try:
            # Phase 1: Setup infrastructure
            logger.info("üìã Phase 1: Infrastructure Setup")
            await self._create_directories()
            await self.env_generator.generate_all_envs()
            
            # Phase 2: Database simulation
            logger.info("üìã Phase 2: Database Simulation")
            await self.db_simulator.create_mock_databases()
            
            # Phase 3: ML model simulation
            logger.info("üìã Phase 3: ML Model Simulation")
            await self.ultralytics_simulator.setup_mock_models()
            
            # Phase 4: Service awakening
            if mode in ['full', 'services']:
                logger.info("üìã Phase 4: Service Awakening")
                await self.service_orchestrator.wake_all_services()
            
            # Phase 5: Health verification
            logger.info("üìã Phase 5: Health Verification")
            await self._verify_system_health()
            
            logger.info("üéâ Universal Dummy System is now AWAKE!")
            await self._print_system_status()
            
            # Keep system running
            if mode == 'full':
                await self._keep_alive()
                
        except Exception as e:
            logger.error(f"‚ùå System awakening failed: {e}")
            raise
    
    async def _create_directories(self):
        """Create necessary directory structure"""
        directories = [
            'data/mock_databases',
            'data/models/mock_ultralytics',
            'data/exports',
            'data/screenshots',
            'logs',
            'config/secrets',
            'meta_automation/config',
            'telegram_automation/config',
            'telegram_automation/logs'
        ]
        
        for directory in directories:
            dir_path = self.project_root / directory
            dir_path.mkdir(parents=True, exist_ok=True)
        
        logger.info("‚úÖ Directory structure created")
    
    async def _verify_system_health(self):
        """Verify that all system components are healthy"""
        health_checks = []
        
        # Check database files
        db_dir = self.project_root / "data/mock_databases"
        if db_dir.exists():
            health_checks.append("‚úÖ Mock databases created")
        else:
            health_checks.append("‚ùå Mock databases missing")
        
        # Check model files
        models_dir = self.project_root / "data/models/mock_ultralytics"
        if models_dir.exists() and list(models_dir.glob("*.pt")):
            health_checks.append("‚úÖ Mock ML models available")
        else:
            health_checks.append("‚ùå Mock ML models missing")
        
        # Check environment files
        env_files = ['.env', '.env.rama', '.env.meta', '.env.tele']
        existing_envs = [f for f in env_files if (self.project_root / f).exists()]
        health_checks.append(f"‚úÖ Environment files: {len(existing_envs)}/{len(env_files)}")
        
        # Check running services
        active_services = len(self.service_orchestrator.running_processes)
        health_checks.append(f"‚úÖ Active services: {active_services}")
        
        logger.info("üîç System Health Check:")
        for check in health_checks:
            logger.info(f"  {check}")
    
    async def _print_system_status(self):
        """Print current system status"""
        status_info = [
            "",
            "üéØ SYSTEM STATUS DASHBOARD",
            "=" * 50,
            f"üìÅ Project Root: {self.project_root}",
            f"üåø Active Branches: {', '.join(self.active_branches)}",
            f"‚öôÔ∏è Dummy Mode: ENABLED",
            f"üóÑÔ∏è Mock Databases: ACTIVE",
            f"ü§ñ ML Models: SIMULATED",
            f"üì° Services: {len(self.service_orchestrator.running_processes)} running",
            "",
            "üîó Available Endpoints:",
            "  ‚Ä¢ ML API: http://localhost:8000",
            "  ‚Ä¢ API Docs: http://localhost:8000/docs", 
            "  ‚Ä¢ Health Check: http://localhost:8000/health",
            "",
            "üìù Environment Files Generated:",
            "  ‚Ä¢ .env (global)",
            "  ‚Ä¢ .env.rama (TikTok ML)",
            "  ‚Ä¢ .env.meta (Meta Ads)",
            "  ‚Ä¢ .env.tele (Like4Like)",
            "",
            "üóÑÔ∏è Mock Databases Available:",
            "  ‚Ä¢ PostgreSQL (SQLite mock)",
            "  ‚Ä¢ MongoDB (JSON mock)",
            "  ‚Ä¢ Redis (JSON mock)",
            "",
            "üöÄ Next Steps:",
            "  1. Customize environment variables in .env files",
            "  2. Add real API keys when ready for production",
            "  3. Replace mock implementations with real ones",
            "  4. Use 'python awakener.py --stop' to shut down",
            "",
            "=" * 50
        ]
        
        for line in status_info:
            logger.info(line)
    
    async def _keep_alive(self):
        """Keep the system running until interrupted"""
        logger.info("üí§ System running... Press Ctrl+C to stop")
        
        try:
            while True:
                await asyncio.sleep(30)
                logger.debug("üîÑ System heartbeat")
        except KeyboardInterrupt:
            logger.info("üõë Shutdown signal received")
            await self.service_orchestrator.stop_all_services()
    
    async def shutdown(self):
        """Gracefully shutdown the system"""
        logger.info("üîÑ Shutting down Universal Dummy System...")
        await self.service_orchestrator.stop_all_services()
        logger.info("‚úÖ System shutdown complete")


async def main():
    """Main entry point"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Universal Dummy Mode Awakener')
    parser.add_argument('--mode', choices=['basic', 'full', 'services'], default='full',
                        help='Awakening mode')
    parser.add_argument('--branches', nargs='+', choices=['rama', 'meta', 'tele'],
                        default=['rama', 'meta', 'tele'], help='Branches to activate')
    parser.add_argument('--project-root', help='Project root directory')
    parser.add_argument('--stop', action='store_true', help='Stop all services')
    
    args = parser.parse_args()
    
    # Create awakener instance
    awakener = UniversalAwakener(
        project_root=args.project_root,
        branches=args.branches
    )
    
    if args.stop:
        await awakener.shutdown()
    else:
        await awakener.awaken_system(mode=args.mode)


if __name__ == "__main__":
    asyncio.run(main())